# -*- coding: utf-8 -*-
"""Fake News Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bFZoX6oNdpvZLUUj2Wfi3ga21uw2xMtI

**train.csv: A full training dataset with the following attributes:**

id: unique id for a news article
title: the title of a news article
author: author of the news article
text: the text of the article; could be incomplete
label: a label that marks the article as potentially unreliable

> 1: fake

> 0: real

Importing the dependencies
"""

import numpy as np

import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

import nltk
nltk.download('stopwords')

#printing the stopwords in english
print(stopwords.words('english'))

"""Data Pre-processing"""

# loading the dataset to a pandas data frame
# pandas dataset loads the dataset into a more structured table
news_dataset = pd.read_csv('/content/train.csv.zip')

#checking the size of our dataset, (a,b) = first element will give no of rows and second will give no of columns
news_dataset.shape

#printing first 5 rows of our dataset
news_dataset.head()

# counting the no of missing values in our dataset
news_dataset.isnull().sum()

#replacing missing values with empty strings (or null values)
news_dataset = news_dataset.fillna('')

# merging the author name and news titles
news_dataset['content'] = news_dataset['author'] + " " + news_dataset['title']

#printing the content column
print(news_dataset['content'])

#separating data(content column) and label
# for separating content and label, we'll put label column in a new variable called X.
# dataset_name.drop(columns = 'column name', axis = 0(for rows)/1(for columns)
# drop is used to remove rows or columns from the given dataset.
X = news_dataset.drop(columns = 'label', axis = 1)

# putting the label column is another variable Y
Y = news_dataset['label']

#printing X and Y
print('X')
print('Y')

"""Stemming:
Stemming is the process of reducing a word to its root word by removing their prefices and suffices.

eg. actor, actress, acting
root word = **act** (removes rest of the prefix and suffix)

it is a v imp step as it helps to reduce the number of words so that our model gives a better performance.
We'll use the porterStemmer function that we imported above.

next step will be Vectorizing
vectorizing means turning our text data to its feature vectors that is numerical data that we can feed to our machine learning model.
"""

port_stem = PorterStemmer()

def stemming(content):
  stemmed_content = re.sub('[^a-zA-Z]', ' ', content)
  stemmed_content = stemmed_content.lower()
  stemmed_content = stemmed_content.split()
  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
  stemmed_content = ' '.join(stemmed_content)
  return stemmed_content

#applying stemming function to our content column
news_dataset['content'] = news_dataset['content'].apply(stemming)

print(news_dataset['content'])

#separate the data and label
X = news_dataset['content'].values
Y = news_dataset['label'].values

print(X)

print(Y)

"""1 = fake news
0 = real news
"""

Y.shape

# converting the textual data to numerical data
vectorizer = TfidfVectorizer()
vectorizer.fit(X)

X = vectorizer.transform(X)

print(X)

"""splitting the dataset (X and Y) to training and test data

training data is kept in X_train
labels of X_train are stored in Y_train
labels of X_test are stored in Y_test
"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state=2)

"""Training the model: Logistic Regression Model"""

model = LogisticRegression()

"""model.fit trains our model and since we want to train our data only of training set, hence we will write X_train and Y_train."""

model.fit(X_train, Y_train)

"""Evaluation (Finding Accuracy Score)
The model will be asked to predict values and predicted values will be compared to the label values.
"""

# accuracy score on the training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print("Accuracy Score of training data : ", training_data_accuracy)

# accuracy score on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print("Accuracy Score of test data : ", test_data_accuracy)

"""Making a predictive system"""

X_new = X_test[0]
 prediction = model.predict(X_new)
 print(prediction)

 if (prediction[0] is 0):
   print("News is real")
 else:
   print("News is fake")

"""checking if our output was correct or not

"""

print(Y_test[0])

X_new = X_test[57]
prediction1 = model.predict(X_new)
print(prediction1)
if (prediction[0] is 0):
  print("News is real")
else:
  print("News is fake")

print(Y_test[57])

